# Semantic Caching MVP Configuration
# This file records all model/seed/params for reproducibility

seed: 42
max_eval_samples: 1000

# Embedding configuration
embedding:
  model: "sentence-transformers/all-MiniLM-L6-v2"
  device: "cpu"  # or "cuda" for GPU
  pooling: "mean"
  normalize: true

# Cache backend configuration
cache:
  backend: "faiss"  # "faiss" or "sqlite"
  similarity_threshold: 0.85  # Fixed baseline threshold
  top_k: 5  # Number of neighbors for density-based evaluation

# Adaptive threshold settings
adaptive_thresholds:
  length_based:
    short_query_words: 5
    long_query_words: 10
    short_threshold: 0.92
    medium_threshold: 0.85
    long_threshold: 0.78
  
  density_based:
    top_k: 5
    high_density_threshold: 0.90
    low_density_threshold: 0.80
    density_cutoff: 0.75  # Average similarity above this is "dense"
  
  score_gap:
    small_gap_threshold: 0.92
    large_gap_threshold: 0.78
    gap_cutoff: 0.1  # Gap below this is "small"

# LLM Backend configuration
llm:
  mode: "hf"  # "hf" or maybe different adapter in future
  
  # Hugging Face settings
  hf:
    model: "gpt2"
    max_new_tokens: 150
    temperature: 0.7
    # API token loaded from .env file

# Evaluation settings
evaluation:
  compute_confidence_intervals: true
  confidence_level: 0.95
  log_per_query: true
  output_dir: "results"
